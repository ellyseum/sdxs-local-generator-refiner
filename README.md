# SDXS Generator & Refiner

A powerful web application for generating and refining images locally using Stable Diffusion XS models from HuggingFace.

## Features

- üöÄ Download and load SD-XS models directly from HuggingFace
- üé® Generate images locally using PyTorch + Diffusers
- ‚ú® **NEW:** Refine generated images with img2img pipelines
- üîÑ **NEW:** Multiple refiner model options (SDXS, Small SD V0)
- üíæ Save generated and refined images to local storage
- üñ•Ô∏è Clean, intuitive web interface with conditional workflows
- ‚ö° Fast inference with optimized settings

## Tech Stack

- **Backend**: FastAPI (Python) with PyTorch + Diffusers
- **Frontend**: React with Tailwind CSS + shadcn/ui components
- **Inference**: PyTorch with diffusers library
- **Storage**: Local file system

## Installation & Setup

### Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.9+** ([Download](https://www.python.org/downloads/))
- **Node.js 16+** and **npm/yarn** ([Download](https://nodejs.org/))
- **Git** ([Download](https://git-scm.com/downloads))
- **Optional but recommended:** CUDA-compatible GPU with drivers for faster inference

### Step 1: Clone the Repository

```bash
git clone <your-repo-url>
cd sdxs-generator-refiner
```

### Step 2: Backend Setup

#### Install Python Dependencies

```bash
cd backend

# Create a virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### Backend Dependencies Include:
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `torch` - PyTorch for model inference
- `diffusers` - HuggingFace diffusers library
- `transformers` - Model components
- `huggingface-hub` - Model downloading
- `Pillow` - Image processing

#### Create Environment File (Optional)

Create a `.env` file in the `backend` directory if you need custom configuration:

```bash
# backend/.env
CORS_ORIGINS=http://localhost:3000
```

### Step 3: Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install
# or with yarn:
yarn install
```

#### Frontend Dependencies Include:
- `react` - UI framework
- `axios` - HTTP client
- `tailwindcss` - Styling
- `shadcn/ui` - UI components

#### Create Environment File

Create a `.env` file in the `frontend` directory:

```bash
# frontend/.env
REACT_APP_BACKEND_URL=http://localhost:8001
```

### Step 4: Run the Application

You'll need two terminal windows/tabs:

#### Terminal 1: Start Backend

```bash
cd backend
# Activate virtual environment if not already activated
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Run the server
uvicorn server:app --reload --host 0.0.0.0 --port 8001
```

Backend will be available at `http://localhost:8001`

#### Terminal 2: Start Frontend

```bash
cd frontend

# Start development server
npm start
# or with yarn:
yarn start
```

Frontend will be available at `http://localhost:3000`

### Step 5: First Use

1. Open your browser and navigate to `http://localhost:3000`
2. Enter the SD-XS model URL: `https://huggingface.co/IDKiro/sdxs-512-0.9`
3. Click "Fetch & Load Model" (first download takes 1-2 minutes)
4. Enter a prompt and click "Generate"
5. Once image is generated, try the refiner feature below!

## How It Works

### 1. Model Loading

When you click "Fetch & Load Model":

1. The app parses the HuggingFace model URL to extract the repo ID
2. Downloads the model files using `huggingface_hub.snapshot_download()`
3. Loads the model into memory using the `diffusers` library
4. Caches the pipeline for fast subsequent generations
5. **Automatically links to refiner service** for SDXS refinement

### 2. Image Generation

When you click "Generate":

1. Takes your text prompt
2. Runs the SD-XS diffusion pipeline (default: 8 steps, 512x512)
3. Saves the generated PNG to `./data/images/`
4. Displays the image in the UI
5. **Reveals the refiner section** below the generated image

### 3. Image Refinement (NEW)

After image generation, you can refine your images:

1. **Select refiner model:**
   - **SDXS (Already Loaded)** - Uses the existing SD-XS model (instant, no download)
   - **Small Stable Diffusion V0** - Lightweight 0.76B parameter model (requires download)

2. **For Small SD V0:** Click "Fetch & Load Refiner Model" (one-time setup)

3. **Enter refinement prompt:**
   - Describe modifications: "make it more vibrant and colorful"
   - Add details: "add dramatic lighting"
   - Change style: "make it look like an oil painting"

4. **Click "Refine Image"**:
   - Runs img2img diffusion (strength=0.75, 20 steps)
   - Saves refined image to `./data/images/refined/`
   - Displays the refined result below

## Supported Models

The app works with SD-XS (Stable Diffusion XS) models and lightweight Stable Diffusion models compatible with the `diffusers` library.

### Generation Models (SD-XS)

- **IDKiro/sdxs-512-0.9** - SD-XS 512x512 model (recommended, ~1-2GB)

### Refiner Models

- **SDXS (Built-in)** - Uses the loaded SD-XS model for refinement (no extra download)
- **OFA-Sys/small-stable-diffusion-v0** - Compact 0.76B parameter model (~2GB download)

## API Endpoints

### Generation Endpoints

#### `POST /api/model/prepare`
Loads a generation model from HuggingFace.

**Request:**
```json
{
  "modelCardUrl": "https://huggingface.co/IDKiro/sdxs-512-0.9"
}
```

#### `POST /api/generate`
Generates an image from a text prompt.

**Request:**
```json
{
  "prompt": "a beautiful sunset over mountains",
  "size": "512x512",
  "steps": 8,
  "guidance": 4.0,
  "seed": null
}
```

#### `GET /api/images/{filename}`
Serves a generated image file.

### Refiner Endpoints (NEW)

#### `POST /api/refiner/prepare`
Loads a refiner model (Small SD V0 only, SDXS auto-loaded).

**Request:**
```json
{
  "modelCardUrl": "https://huggingface.co/OFA-Sys/small-stable-diffusion-v0",
  "modelType": "small-sd-v0"
}
```

#### `POST /api/refiner/refine`
Refines an image using img2img pipeline.

**Request:**
```json
{
  "originalImageFilename": "image.png",
  "refinementPrompt": "make it more vibrant",
  "modelType": "sdxs",
  "strength": 0.75,
  "steps": 20,
  "guidance": 7.5
}
```

#### `GET /api/images/refined/{filename}`
Serves a refined image file.

## Configuration

### Generation Parameters

- **size**: Image dimensions (default: `512x512`)
- **steps**: Number of inference steps (default: `8` for generation)
- **guidance**: Guidance scale (default: `4.0` for generation)
- **seed**: Random seed for reproducibility (optional)

### Refinement Parameters (NEW)

- **strength**: How much to transform the image (default: `0.75`, range: 0.0-1.0)
  - Lower values = more faithful to original
  - Higher values = more creative changes
- **steps**: Number of refinement steps (default: `20`)
- **guidance**: Guidance scale for refinement (default: `7.5`)

### Performance

- **CPU Mode**: Works but slower
  - Generation: ~30-60s per image
  - Refinement: ~60-90s per image
- **GPU Mode**: Much faster if CUDA is available
  - Generation: ~2-5s per image
  - Refinement: ~5-10s per image

The app automatically detects and uses GPU if available.

## Project Structure

```
/app/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ server.py                    # Main FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hf_downloader.py        # HuggingFace model downloader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py         # Model loading service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py             # SD-XS generation pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ refiner.py              # Image refinement service (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ *.png               # Generated images
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ refined/            # Refined images (NEW)
‚îÇ   ‚îî‚îÄ‚îÄ models/                     # Downloaded models cache
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ App.js                  # Main React component
‚îÇ       ‚îî‚îÄ‚îÄ components/ui/          # shadcn/ui components
‚îî‚îÄ‚îÄ README.md
```

## Notes

- All inference is local - no cloud API calls except initial HuggingFace downloads
- Generated images are saved permanently in `./data/images/`
- Refined images are saved separately in `./data/images/refined/`
- Models are cached in `./models/` directory for reuse
- SDXS refiner uses the same model as generation (memory efficient)
- Small SD V0 refiner requires separate download but offers alternative results

## Tips for Best Results

### Generation
- Use descriptive prompts: "a serene mountain landscape at sunset with purple clouds"
- Keep prompts focused and specific
- Default 8 steps work well for SD-XS models

### Refinement
- Use refinement prompts to describe changes, not recreate the entire scene
- Examples:
  - ‚úÖ "make colors more vibrant"
  - ‚úÖ "add dramatic lighting"
  - ‚úÖ "enhance details and sharpness"
  - ‚ùå "a completely different scene" (better to generate new)
- Adjust strength parameter:
  - 0.5-0.7: Subtle refinements
  - 0.7-0.8: Moderate changes (default: 0.75)
  - 0.8-1.0: Dramatic transformations
- Try both SDXS and Small SD V0 refiners for different results


## Troubleshooting

### Backend Issues

**Problem: `ModuleNotFoundError` or `ImportError`**
```bash
# Make sure virtual environment is activated
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows

# Reinstall dependencies
pip install -r requirements.txt
```

**Problem: PyTorch not detecting GPU**
```bash
# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"

# If False, install CUDA-compatible PyTorch
# Visit: https://pytorch.org/get-started/locally/
```

**Problem: Out of memory errors**
- Models require significant RAM/VRAM
- SD-XS: ~4-6GB RAM (CPU) or ~2-4GB VRAM (GPU)
- Small SD V0: ~3-5GB RAM (CPU) or ~2-3GB VRAM (GPU)
- Close other applications or use smaller batch sizes

**Problem: Model download fails**
```bash
# Check your internet connection
# HuggingFace downloads can be large (1-2GB)
# Try again or manually download from HuggingFace
```

### Frontend Issues

**Problem: `CORS` errors in browser console**
- Check that backend `.env` has correct CORS_ORIGINS
- Verify backend is running on port 8001
- Check frontend `.env` has correct REACT_APP_BACKEND_URL

**Problem: Frontend won't start**
```bash
# Clear node modules and reinstall
rm -rf node_modules package-lock.json
npm install

# Or with yarn
rm -rf node_modules yarn.lock
yarn install
```

**Problem: Images not displaying**
- Check browser console for errors
- Verify image paths start with `/api/images/`
- Check that backend is serving files correctly
- Clear browser cache

### General Issues

**Problem: Slow generation/refinement**
- This is normal on CPU (30-90 seconds)
- Consider using a GPU for 10-20x speedup
- Reduce steps parameter (minimum: 4 for generation, 10 for refinement)

**Problem: Port already in use**
```bash
# Backend (port 8001)
# Find and kill process
lsof -ti:8001 | xargs kill -9  # macOS/Linux
netstat -ano | findstr :8001   # Windows

# Frontend (port 3000)
lsof -ti:3000 | xargs kill -9  # macOS/Linux
netstat -ano | findstr :3000   # Windows
```

## System Requirements

### Minimum
- **CPU**: 4+ cores
- **RAM**: 8GB (CPU inference)
- **Storage**: 10GB free space (for models)
- **OS**: Windows 10+, macOS 10.15+, or Linux

### Recommended
- **CPU**: 8+ cores
- **RAM**: 16GB
- **GPU**: NVIDIA GPU with 6GB+ VRAM (CUDA compatible)
- **Storage**: 20GB free space (for multiple models)
- **OS**: Linux with NVIDIA drivers

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is open source and available under the MIT License.

## Acknowledgments

- Built with [HuggingFace Diffusers](https://github.com/huggingface/diffusers)
- UI components from [shadcn/ui](https://ui.shadcn.com/)
- Models from [HuggingFace Model Hub](https://huggingface.co/models)

